{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity and community extraction for all matices files\n",
    "#### Quantifys modularity and plots topology maps and gemomentric maps based on communities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ColorConverter\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "\n",
    "# Directory of Excel files\n",
    "input_dir = r\"D:\\MEA_Analysis\\.....\\21_02_Thresholded_Fils_Concatinated\"\n",
    "output_dir = r\"D:\\......\\ModularityExcel_Res_x.x\"\n",
    "# Define the output directory\n",
    "output_dir_plots = r\"D:\\........\\ModularityPlots_Res_x.x\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_dir_plots, exist_ok=True)\n",
    "\n",
    "\n",
    "# Iterate over each Excel file in the directory\n",
    "for excel_file in os.listdir(input_dir):\n",
    "    if excel_file.endswith('.xlsx'):\n",
    "        file_path = os.path.join(input_dir, excel_file)\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        \n",
    "        # Remove the '.xlsx' extension and extract the last 3 digits before .xlsx\n",
    "        file_prefix = excel_file[:-5][-3:]\n",
    "        # Create new prefix by adding 'Thre_' to the extracted part\n",
    "        new_file_prefix = f'Ther_{file_prefix}_'\n",
    "\n",
    "        # Initialize a list to store results for each sheet\n",
    "        results = []\n",
    "        # Initialize a dictionary to store community DataFrames for each sheet\n",
    "        community_dfs = {}\n",
    "        \n",
    "        # Iterate over each sheet (sample) in the Excel file\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            data = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            neuron_names = data.iloc[:, 0].values\n",
    "\n",
    "            # Sort correlation matrix based on neuron_names order\n",
    "            correlation_matrix = data.iloc[:, 5:].copy()\n",
    "            correlation_matrix.columns = neuron_names\n",
    "            correlation_matrix.index = neuron_names\n",
    "            correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "            correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "            np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "            \n",
    "            ######## Use escel file name extracted Threshold value  to set threshold for weighted-G #####\n",
    "            \n",
    "            # Convert the extracted string to a float\n",
    "            threshold_value = float(file_prefix)\n",
    "            \n",
    "            \n",
    "            ############################# Create a weighted graph  ##########################\n",
    "            G = nx.Graph()\n",
    "            for i, neuron_i in enumerate(neuron_names):\n",
    "                for j, neuron_j in enumerate(neuron_names):\n",
    "                    if i < j:\n",
    "                        correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "                        if correlation_coefficient > 0.1:  # Set threshold \n",
    "                            G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "            \n",
    "            ############################# Modularity and community detection ####################\n",
    "            \n",
    "            # Community detection using Louvain method\n",
    "        \n",
    "            partition = community_louvain.best_partition(G, resolution=1.0)    ## define resolutioin\n",
    "            \n",
    "            community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "            for neuron, community_id in partition.items():\n",
    "                community_list[community_id].append(neuron)\n",
    "            \n",
    "            # Calculate modularity\n",
    "            Q = nx.community.modularity(G, community_list)\n",
    "            num_communities = len(community_list)\n",
    "            avg_community_size = np.mean([len(community) for community in community_list])\n",
    "            \n",
    "            # Append results for this sheet to the list\n",
    "            results.append([excel_file, sheet_name, Q, num_communities, avg_community_size])\n",
    "\n",
    "            print(\"Modularity (Q) =\", Q)\n",
    "            print(community_list)    \n",
    "\n",
    "            # Extract x and y positions of nodes   ## was not used in this code\n",
    "            x_positions = data.iloc[:, 1].values  # Assuming x positions are in the second column\n",
    "            y_positions = data.iloc[:, 2].values  # Assuming y positions are in the third column\n",
    "\n",
    "            # Calculate node degrees\n",
    "            node_degrees = dict(G.degree())\n",
    "\n",
    "            # Define community colors\n",
    "            community_colors = [f\"C{idx}\" for idx in range(len(community_list))]\n",
    "\n",
    "            # Define lighter colors for communities\n",
    "            lighter_community_colors = []\n",
    "            for color in community_colors:\n",
    "                rgb_color = ColorConverter().to_rgb(color)\n",
    "                lighter_color = tuple([min(1, c + 0.3) for c in rgb_color])  # Adjust the increment (0.3) as needed\n",
    "                lighter_community_colors.append(lighter_color)\n",
    "\n",
    "            \n",
    "            \n",
    "            ###################################### Plot Geoometric Connectivity Maps ######################################   \n",
    "\n",
    "            # Plot communities based on real position\n",
    "            plt.figure(figsize=(12, 5))\n",
    "\n",
    "            # Plot based on real position\n",
    "            plt.subplot(1, 2, 1)\n",
    "\n",
    "            plt.gca().set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "            community_colors = [f\"C{idx}\" for idx in range(len(community_list))]  # Generate community colors\n",
    "            for source, target in G.edges():\n",
    "                pos_src = (x_positions[neuron_names == source][0], y_positions[neuron_names == source][0])\n",
    "                pos_tgt = (x_positions[neuron_names == target][0], y_positions[neuron_names == target][0])\n",
    "                plt.annotate(\"\",\n",
    "                             xy=pos_src, xycoords='data',\n",
    "                             xytext=pos_tgt, textcoords='data',\n",
    "                             arrowprops=dict(arrowstyle=\"-\", color='gray', alpha=0.4, linewidth=0.3,\n",
    "                                             connectionstyle=\"arc3,rad=0.2\", zorder=1))  # Adjust the curvature with rad parameter\n",
    "\n",
    "            for idx, (community, color) in enumerate(zip(community_list, lighter_community_colors)):  # Use lighter colors\n",
    "                community_x = x_positions[np.isin(neuron_names, community)]\n",
    "                community_y = y_positions[np.isin(neuron_names, community)]\n",
    "\n",
    "                # Add jitter to x and y positions\n",
    "                jittered_community_x = [x + random.uniform(-30, 30) for x in community_x]\n",
    "                jittered_community_y = [y + random.uniform(-30, 30) for y in community_y]\n",
    "\n",
    "                community_degrees = [node_degrees[node] for node in community]\n",
    "                node_size = [deg * 3 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "                plt.scatter(jittered_community_x, jittered_community_y, label=f'Community {idx + 1}',\n",
    "                            s=node_size, c=color, zorder=3, edgecolor='black', linewidth=0.3)\n",
    "\n",
    "            print(excel_file, '-------------------')\n",
    "            plt.xlabel('X Position')\n",
    "            plt.ylabel('Y Position')\n",
    "            plt.title(f'{sheet_name}_Network Community Visualization (Real Position)')\n",
    "            plt.grid(True, color='gray', alpha=0.2, linewidth=0.5)  # Adjust grid lines\n",
    "            plt.axis('equal')  # Ensure aspect ratio is equal\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            # Adjust the y-axis limits to -200 and 1600\n",
    "            plt.ylim(-200, 1600)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #### in case you want to extract only geometry plot ####\n",
    "            # Use the new prefix in the filename for saving the plot\n",
    "            #plot_filename = f'{new_file_prefix}{sheet_name}_NetComPlot'\n",
    "            # Save the plot as PDF with the sheet name included\n",
    "            #plt.savefig(os.path.join(output_dir_plots, f'{plot_filename}_Geometry.pdf'), format='pdf')\n",
    "            # Save the plot as SVG\n",
    "            #plt.savefig(os.path.join(output_dir_plots, f'{plot_filename}_Geometry.svg'), format='svg')\n",
    "\n",
    "\n",
    "            ###################### Plot based on topology --- using Kamada-Kawai layout\n",
    "            plt.subplot(1, 2, 2)\n",
    "            pos = nx.kamada_kawai_layout(G, scale=2.0)  # Using Kamada-Kawai layout with increased scale for node separation\n",
    "            for idx, (community, color) in enumerate(zip(community_list, lighter_community_colors)):  # Use lighter colors\n",
    "                community_degrees = [node_degrees[node] for node in community]\n",
    "                node_size = [deg * 3 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "\n",
    "                plt.scatter([pos[node][0] for node in community], [pos[node][1] for node in community], label=f'Community {idx + 1}',\n",
    "                            s=node_size, c=color, zorder=3, edgecolor='black', linewidth=0.3)\n",
    "\n",
    "\n",
    "            for source, target in G.edges():\n",
    "                pos_src = pos[source]\n",
    "                pos_tgt = pos[target]\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=[(source, target)], \n",
    "                                       width=0.2, alpha=0.9, connectionstyle=\"arc3,rad=0.2\",\n",
    "                                       edge_color='gray')  # Curved edges without arrowheads\n",
    "\n",
    "            print(excel_file, '-------------------')\n",
    "            plt.title(f'{sheet_name}_Network Community Visualization (Kamada-Kawai Layout)')\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            ########### Save Geometry-based  and Topology_based  plots together\n",
    "            # Use the new prefix in the filename for saving the plot\n",
    "            plot_filename = f'{new_file_prefix}{sheet_name}_NetComPlot'\n",
    "            # Save the plot as PDF\n",
    "            plt.savefig(os.path.join(output_dir_plots, f'{plot_filename}_Topology.pdf'), format='pdf')\n",
    "            # Save the plot as SVG\n",
    "            plt.savefig(os.path.join(output_dir_plots, f'{plot_filename}_Topology.svg'), format='svg')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            ############################################ Plot community-based Hetmaps #################################\n",
    "\n",
    "            # Print communities\n",
    "            for idx, community in enumerate(community_list):\n",
    "                print(f\"Community {idx + 1}: {community}\")\n",
    "\n",
    "            # Extract ordered neurons  (neurons that are within communities will be selected)\n",
    "            ordered_neurons = [neuron for community in community_list for neuron in community]\n",
    "\n",
    "            # Create a symmetric correlation matrix with ordered neurons\n",
    "            # first: generates list of node pairs with their correlation coefficient attributed. \n",
    "            # Then: it generates a symmetric matrix based on list \n",
    "            ordered_data = pd.DataFrame(index=ordered_neurons, columns=ordered_neurons)\n",
    "            for i, neuron_i in enumerate(ordered_neurons):\n",
    "                for j, neuron_j in enumerate(ordered_neurons):\n",
    "                    correlation_coefficient = correlation_matrix.loc[neuron_i, neuron_j]\n",
    "                    ordered_data.at[neuron_i, neuron_j] = correlation_coefficient\n",
    "                    ordered_data.at[neuron_j, neuron_i] = correlation_coefficient\n",
    "\n",
    "\n",
    "            # Ensure diagonal is zero\n",
    "            np.fill_diagonal(ordered_data.values, 0)\n",
    "\n",
    "            # Convert correlation coefficients to floats\n",
    "            ordered_data = ordered_data.astype(float)\n",
    "\n",
    "            # Plot the heatmap\n",
    "            plt.figure(figsize=(7, 5))\n",
    "\n",
    "            # Plot the heatmap with grayscale colormap\n",
    "            sns.heatmap(ordered_data, cmap='Greys', vmin=ordered_data.values.max(), vmax=ordered_data.values.min(),\n",
    "                        linewidths=0.5, linecolor='black', alpha=0.5, cbar=True, square=True, mask=ordered_data.isnull(),\n",
    "                        annot=False, fmt='.2f')\n",
    "\n",
    "            # Draw squares around neurons of each community with respective colors\n",
    "            ax = plt.gca()\n",
    "            start = 0\n",
    "            for idx, community in enumerate(community_list):\n",
    "                end = start + len(community)\n",
    "                color = community_colors[idx]\n",
    "                rect = plt.Rectangle((start, start), end - start, end - start, linewidth=1, edgecolor=color, facecolor=color, alpha=0.5)\n",
    "                ax.add_patch(rect)\n",
    "                start = end\n",
    "\n",
    "            print(excel_file, '-------------------')\n",
    "            plt.title(f'{sheet_name}_Community-Based Correlation Matrix Heatmap')\n",
    "            plt.xlabel('Neurons')\n",
    "            plt.ylabel('Neurons')\n",
    "\n",
    "            \n",
    "            # Use the new prefix in the filename for saving the plot\n",
    "            plot_filename = f'{new_file_prefix}{sheet_name}_NetComPlot'\n",
    "            # Save the plot as PDF\n",
    "            plt.savefig(os.path.join(output_dir_plots, f'{plot_filename}_HeatMap.pdf'), format='pdf')\n",
    "            # Save the plot as SVG\n",
    "            plt.savefig(os.path.join(output_dir_plots, f'{plot_filename}_HeatMap.svg'), format='svg')\n",
    "            plt.show()\n",
    "            \n",
    "            ######################################################################################################\n",
    "            ######################################################################################################\n",
    "            ######## EXPORT Community data ##############\n",
    "            \n",
    "            # Export the list of neurons in each detected community to a separate DataFrame\n",
    "            community_df = pd.DataFrame([(community_id, neuron) for community_id, community in enumerate(community_list) for neuron in community], columns=['Community', 'Neuron'])\n",
    "            \n",
    "            # Store community DataFrame for this sheet in the dictionary\n",
    "            community_dfs[sheet_name] = community_df\n",
    "            \n",
    "            \n",
    "            # Export the list of neurons in each detected community to a separate Excel file\n",
    "            #community_df = pd.DataFrame([(community_id, neuron) for community_id, community in enumerate(community_list) for neuron in community], columns=['Community', 'Neuron'])\n",
    "            #community_df.to_excel(os.path.join(output_dir, f\"{excel_file}_{sheet_name}_communities.xlsx\"), index=False)\n",
    "\n",
    "        # Create a DataFrame from the results list\n",
    "        results_df = pd.DataFrame(results, columns=['Source Excel File', 'Source Excel Sheet', 'Modularity (Q)', 'Number of Communities', 'Average Community Size'])\n",
    "        \n",
    "        # Export the results DataFrame to an Excel file\n",
    "        results_df.to_excel(os.path.join(output_dir, f\"{excel_file}_results.xlsx\"), index=False)\n",
    "        \n",
    "        # Export community DataFrames to a single Excel file\n",
    "        with pd.ExcelWriter(os.path.join(output_dir, f\"{excel_file}_communities.xlsx\")) as writer:\n",
    "            for sheet_name, df in community_dfs.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whole network modularity score based on Louvain method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0:  # Consider only positive correlations\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Relabel the nodes\n",
    "G = nx.relabel.relabel_nodes(G, dict(enumerate(correlation_matrix.columns)), copy=True)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "communities = greedy_modularity_communities(G)\n",
    "community_list = [list(community) for community in communities]\n",
    "\n",
    "# Calculate modularity\n",
    "Q = nx.community.modularity(G, community_list)\n",
    "\n",
    "print(\"Modularity (Q) =\", Q)\n",
    "print (communities)\n",
    "print(community_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modularity and communities based on Louvian -> greedy modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Consider that neurons that are outside of the communities will not be included in the communitys and will not be exported\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "correlation_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.0:  # Consider if threshold has not been applied before\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Relabel the nodes\n",
    "G = nx.relabel.relabel_nodes(G, dict(enumerate(correlation_matrix.columns)), copy=True)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "communities = greedy_modularity_communities(G)\n",
    "community_list = [list(community) for community in communities]\n",
    "\n",
    "# Create a mapping dictionary for node indices to neuron names\n",
    "index_to_neuron = {i: neuron_names[i] for i in range(len(neuron_names))}\n",
    "\n",
    "print(\"Length of neuron_names:\", len(neuron_names))\n",
    "print(\"Length of index_to_neuron:\", len(index_to_neuron))\n",
    "\n",
    "# Convert community lists from node indices to neuron names, excluding nodes not in index_to_neuron\n",
    "neuron_community_list = [[index_to_neuron[node_index] for node_index in community if node_index in index_to_neuron] for community in community_list]\n",
    "\n",
    "print(\"Length of neuron_names:\", len(neuron_names))\n",
    "print(\"Length of index_to_neuron:\", len(index_to_neuron))\n",
    "print(\"Number of communities:\", len(community_list))\n",
    "\n",
    "\n",
    "# Calculate modularity\n",
    "Q = nx.community.modularity(G, community_list)\n",
    "\n",
    "print(\"Modularity (Q) =\", Q)\n",
    "print(\"Communities:\")\n",
    "for i, community in enumerate(neuron_community_list):\n",
    "    print(f\"Community {i + 1}: {community}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modularity and communities based on Louvian -> best_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.60:  # Threshold\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Print communities\n",
    "for idx, community in enumerate(community_list):\n",
    "    print(f\"Community {idx + 1}: {community}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot_communities_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.60:  # Consider threshold\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Extract x and y positions of nodes\n",
    "x_positions = data.iloc[:, 1].values  # Assuming x positions are in the second column\n",
    "y_positions = data.iloc[:, 2].values  # Assuming y positions are in the third column\n",
    "\n",
    "# Plot communities based on real position\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot based on real position\n",
    "plt.subplot(1, 2, 1)\n",
    "for idx, community in enumerate(community_list):\n",
    "    community_x = x_positions[np.isin(neuron_names, community)]\n",
    "    community_y = y_positions[np.isin(neuron_names, community)]\n",
    "    plt.scatter(community_x, community_y, label=f'Community {idx + 1}')\n",
    "\n",
    "    for source in community:\n",
    "        for target in community:\n",
    "            if source != target and G.has_edge(source, target):\n",
    "                plt.plot([x_positions[neuron_names == source][0], x_positions[neuron_names == target][0]],\n",
    "                         [y_positions[neuron_names == source][0], y_positions[neuron_names == target][0]],\n",
    "                         color='gray', alpha=0.3, linewidth=2)  # Adjust the line thickness here\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Network Community Visualization (Real Position)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot based on topological closeness using Kamada-Kawai layout\n",
    "plt.subplot(1, 2, 2)\n",
    "pos = nx.kamada_kawai_layout(G)  # Using Kamada-Kawai layout\n",
    "for idx, community in enumerate(community_list):\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=community, node_color=f\"C{idx}\", node_size=100)\n",
    "nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.7)\n",
    "plt.title('Network Community Visualization (Kamada-Kawai Layout)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot communities_02 (node size takes degree of node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.60:  # Consider Threshold\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Extract x and y positions of nodes\n",
    "x_positions = data.iloc[:, 1].values  # Assuming x positions are in the second column\n",
    "y_positions = data.iloc[:, 2].values  # Assuming y positions are in the third column\n",
    "\n",
    "# Calculate node degrees\n",
    "node_degrees = dict(G.degree())\n",
    "\n",
    "# Plot communities based on real position\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot based on real position\n",
    "plt.subplot(1, 2, 1)\n",
    "community_colors = [f\"C{idx}\" for idx in range(len(community_list))]  # Generate community colors\n",
    "for idx, (community, color) in enumerate(zip(community_list, community_colors)):\n",
    "    community_x = x_positions[np.isin(neuron_names, community)]\n",
    "    community_y = y_positions[np.isin(neuron_names, community)]\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 10 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    plt.scatter(community_x, community_y, label=f'Community {idx + 1}', s=node_size, c=color)\n",
    "\n",
    "    for source in community:\n",
    "        for target in community:\n",
    "            if source != target and G.has_edge(source, target):\n",
    "                plt.plot([x_positions[neuron_names == source][0], x_positions[neuron_names == target][0]],\n",
    "                         [y_positions[neuron_names == source][0], y_positions[neuron_names == target][0]],\n",
    "                         color='gray', alpha=0.3, linewidth=1)  # Adjust the line thickness here\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Network Community Visualization (Real Position)')\n",
    "plt.legend()\n",
    "plt.grid(True, color='gray', alpha=0.2, linewidth=0.5)  # Adjust grid lines\n",
    "plt.axis('equal')  # Ensure aspect ratio is equal\n",
    "\n",
    "# Plot based on topological closeness using Kamada-Kawai layout\n",
    "plt.subplot(1, 2, 2)\n",
    "pos = nx.kamada_kawai_layout(G)  # Using Kamada-Kawai layout\n",
    "for idx, (community, color) in enumerate(zip(community_list, community_colors)):\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 10 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=community, node_color=color, node_size=node_size)\n",
    "nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.7)\n",
    "plt.title('Network Community Visualization (Kamada-Kawai Layout)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot Geometry_based and topology based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.60:  # Consider only positive correlations\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Extract x and y positions of nodes\n",
    "x_positions = data.iloc[:, 1].values  # Assuming x positions are in the second column\n",
    "y_positions = data.iloc[:, 2].values  # Assuming y positions are in the third column\n",
    "\n",
    "# Calculate node degrees\n",
    "node_degrees = dict(G.degree())\n",
    "\n",
    "# Plot communities based on real position\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot based on real position\n",
    "plt.subplot(1, 2, 1)\n",
    "community_colors = [f\"C{idx}\" for idx in range(len(community_list))]  # Generate community colors\n",
    "for source, target in G.edges():\n",
    "    pos_src = (x_positions[neuron_names == source][0], y_positions[neuron_names == source][0])\n",
    "    pos_tgt = (x_positions[neuron_names == target][0], y_positions[neuron_names == target][0])\n",
    "    plt.annotate(\"\",\n",
    "                 xy=pos_src, xycoords='data',\n",
    "                 xytext=pos_tgt, textcoords='data',\n",
    "                 arrowprops=dict(arrowstyle=\"-\", color='gray', alpha=0.3, linewidth=1,\n",
    "                                 connectionstyle=\"arc3,rad=0.2\", zorder=1))  # Adjust the curvature with rad parameter\n",
    "\n",
    "for idx, (community, color) in enumerate(zip(community_list, community_colors)):\n",
    "    community_x = x_positions[np.isin(neuron_names, community)]\n",
    "    community_y = y_positions[np.isin(neuron_names, community)]\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 10 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    plt.scatter(community_x, community_y, label=f'Community {idx + 1}', s=node_size, c=color, zorder=3)\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Network Community Visualization (Real Position)')\n",
    "plt.grid(True, color='gray', alpha=0.2, linewidth=0.5)  # Adjust grid lines\n",
    "plt.axis('equal')  # Ensure aspect ratio is equal\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot based on topological closeness using Kamada-Kawai layout\n",
    "plt.subplot(1, 2, 2)\n",
    "pos = nx.kamada_kawai_layout(G)  # Using Kamada-Kawai layout\n",
    "for idx, (community, color) in enumerate(zip(community_list, community_colors)):\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 10 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=community, node_color=color, node_size=node_size)\n",
    "for source, target in G.edges():\n",
    "    pos_src = pos[source]\n",
    "    pos_tgt = pos[target]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[(source, target)], width=0.5, alpha=0.7, connectionstyle=\"arc3,rad=0.2\", edge_color='gray')  # Curved edges without arrowheads\n",
    "\n",
    "plt.title('Network Community Visualization (Kamada-Kawai Layout)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot_04 _ node color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.60:  # Consider only positive correlations\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Extract x and y positions of nodes\n",
    "x_positions = data.iloc[:, 1].values  # Assuming x positions are in the second column\n",
    "y_positions = data.iloc[:, 2].values  # Assuming y positions are in the third column\n",
    "\n",
    "# Calculate node degrees\n",
    "node_degrees = dict(G.degree())\n",
    "\n",
    "# Define lighter colors for communities\n",
    "lighter_community_colors = []\n",
    "for color in community_colors:\n",
    "    rgb_color = ColorConverter().to_rgb(color)\n",
    "    lighter_color = tuple([min(1, c + 0.3) for c in rgb_color])  # Adjust the increment (0.3) as needed\n",
    "    lighter_community_colors.append(lighter_color)\n",
    "\n",
    "# Plot communities based on real position\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot based on real position\n",
    "plt.subplot(1, 2, 1)\n",
    "community_colors = [f\"C{idx}\" for idx in range(len(community_list))]  # Generate community colors\n",
    "for source, target in G.edges():\n",
    "    pos_src = (x_positions[neuron_names == source][0], y_positions[neuron_names == source][0])\n",
    "    pos_tgt = (x_positions[neuron_names == target][0], y_positions[neuron_names == target][0])\n",
    "    plt.annotate(\"\",\n",
    "                 xy=pos_src, xycoords='data',\n",
    "                 xytext=pos_tgt, textcoords='data',\n",
    "                 arrowprops=dict(arrowstyle=\"-\", color='gray', alpha=0.4, linewidth=1,\n",
    "                                 connectionstyle=\"arc3,rad=0.2\", zorder=1))  # Adjust the curvature with rad parameter\n",
    "\n",
    "for idx, (community, color) in enumerate(zip(community_list, lighter_community_colors)):  # Use lighter colors\n",
    "    community_x = x_positions[np.isin(neuron_names, community)]\n",
    "    community_y = y_positions[np.isin(neuron_names, community)]\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 15 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    plt.scatter(community_x, community_y, label=f'Community {idx + 1}', s=node_size, c=color, zorder=3)\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Network Community Visualization (Real Position)')\n",
    "plt.grid(True, color='gray', alpha=0.2, linewidth=0.5)  # Adjust grid lines\n",
    "plt.axis('equal')  # Ensure aspect ratio is equal\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot based on topological closeness using Kamada-Kawai layout\n",
    "plt.subplot(1, 2, 2)\n",
    "pos = nx.kamada_kawai_layout(G)  # Using Kamada-Kawai layout\n",
    "for idx, (community, color) in enumerate(zip(community_list, lighter_community_colors)):  # Use lighter colors\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 10 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=community, node_color=color, node_size=node_size, alpha=1)  # Set alpha value for lighter color\n",
    "for source, target in G.edges():\n",
    "    pos_src = pos[source]\n",
    "    pos_tgt = pos[target]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[(source, target)], width=0.5, alpha=0.9, connectionstyle=\"arc3,rad=0.2\", edge_color='gray')  # Curved edges without arrowheads\n",
    "\n",
    "plt.title('Network Community Visualization (Kamada-Kawai Layout)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot Heatmap_ Reaorder neurons based on their community to plot the modular heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix.index = neuron_names  # Set index names to neuron names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.60:  # Consider only positive correlations\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Print communities\n",
    "for idx, community in enumerate(community_list):\n",
    "    print(f\"Community {idx + 1}: {community}\")\n",
    "\n",
    "# Extract ordered neurons\n",
    "ordered_neurons = [neuron for community in community_list for neuron in community]\n",
    "\n",
    "# Create a symmetric correlation matrix with ordered neurons\n",
    "ordered_data = pd.DataFrame(index=ordered_neurons, columns=ordered_neurons)\n",
    "for i, neuron_i in enumerate(ordered_neurons):\n",
    "    for j, neuron_j in enumerate(ordered_neurons):\n",
    "        correlation_coefficient = correlation_matrix.loc[neuron_i, neuron_j]\n",
    "        ordered_data.at[neuron_i, neuron_j] = correlation_coefficient\n",
    "        ordered_data.at[neuron_j, neuron_i] = correlation_coefficient\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(ordered_data.values, 0)\n",
    "\n",
    "# Convert correlation coefficients to floats\n",
    "ordered_data = ordered_data.astype(float)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# Create a colormap for community colors\n",
    "num_communities = len(community_list)\n",
    "community_colors = sns.color_palette(\"hsv\", num_communities)\n",
    "community_colormap = ListedColormap(community_colors)\n",
    "\n",
    "sns.heatmap(ordered_data, cmap='Greys_r', vmin=ordered_data.values.min(), vmax=ordered_data.values.max(),\n",
    "            linewidths=0.5, linecolor='black', alpha=0.3, cbar=True, square=True, mask=ordered_data.isnull(),\n",
    "            annot=False, fmt='.2f')\n",
    "\n",
    "# Draw squares around neurons of each community with respective colors\n",
    "ax = plt.gca()\n",
    "start = 0\n",
    "for idx, community in enumerate(community_list):\n",
    "    end = start + len(community)\n",
    "    color = community_colors[idx]\n",
    "    rect = plt.Rectangle((start, start), end - start, end - start, linewidth=1, edgecolor=color, facecolor=color,alpha=0.5 )\n",
    "    ax.add_patch(rect)\n",
    "    start = end\n",
    "\n",
    "plt.title('Community-Based Correlation Matrix Heatmap')\n",
    "plt.xlabel('Neurons')\n",
    "plt.ylabel('Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unified code for community-based topology, geometry maps and  Heat Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ColorConverter\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "\n",
    "# Load your data\n",
    "excel_file = \"Thresholded_Matrix_0.6.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "neuron_names = data.iloc[:, 0].values\n",
    "category = data.iloc[:, 4].values\n",
    "\n",
    "# Sort correlation matrix based on neuron_names order\n",
    "correlation_matrix = data.iloc[:, 5:].copy()\n",
    "correlation_matrix.columns = neuron_names\n",
    "correlation_matrix.index = neuron_names  # Set index names to neuron names\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names, axis=1)\n",
    "correlation_matrix = correlation_matrix.reindex(neuron_names)\n",
    "#print (correlation_matrix)\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "for i, neuron_i in enumerate(neuron_names):\n",
    "    for j, neuron_j in enumerate(neuron_names):\n",
    "        if i < j:  # To avoid duplicates and self-loops\n",
    "            correlation_coefficient = correlation_matrix.iloc[i, j]\n",
    "            if correlation_coefficient > 0.65:  # Consider only positive correlations\n",
    "                G.add_edge(neuron_i, neuron_j, weight=correlation_coefficient)\n",
    "\n",
    "\n",
    "                \n",
    "######################### Extract Communities in each network ###################################            \n",
    "\n",
    "# Community detection using Louvain method\n",
    "partition = community_louvain.best_partition(G, resolution=1.0)  # Adjust the resolution parameter as needed\n",
    "community_list = [[] for _ in range(max(partition.values()) + 1)]\n",
    "for neuron, community_id in partition.items():\n",
    "    community_list[community_id].append(neuron)\n",
    "\n",
    "# Extract x and y positions of nodes\n",
    "x_positions = data.iloc[:, 1].values  # Assuming x positions are in the second column\n",
    "y_positions = data.iloc[:, 2].values  # Assuming y positions are in the third column\n",
    "\n",
    "# Calculate node degrees\n",
    "node_degrees = dict(G.degree())\n",
    "\n",
    "# Define community colors\n",
    "community_colors = [f\"C{idx}\" for idx in range(len(community_list))]\n",
    "\n",
    "# Define lighter colors for communities\n",
    "lighter_community_colors = []\n",
    "for color in community_colors:\n",
    "    rgb_color = ColorConverter().to_rgb(color)\n",
    "    lighter_color = tuple([min(1, c + 0.3) for c in rgb_color])  # Adjust the increment (0.3) as needed\n",
    "    lighter_community_colors.append(lighter_color)\n",
    "\n",
    "###################################### Plot Connectivit Maps ######################################   \n",
    "    \n",
    "# Plot communities based on real position\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot based on real position\n",
    "plt.subplot(1, 2, 1)\n",
    "community_colors = [f\"C{idx}\" for idx in range(len(community_list))]  # Generate community colors\n",
    "for source, target in G.edges():\n",
    "    pos_src = (x_positions[neuron_names == source][0], y_positions[neuron_names == source][0])\n",
    "    pos_tgt = (x_positions[neuron_names == target][0], y_positions[neuron_names == target][0])\n",
    "    plt.annotate(\"\",\n",
    "                 xy=pos_src, xycoords='data',\n",
    "                 xytext=pos_tgt, textcoords='data',\n",
    "                 arrowprops=dict(arrowstyle=\"-\", color='gray', alpha=0.4, linewidth=0.3,\n",
    "                                 connectionstyle=\"arc3,rad=0.2\", zorder=1))  # Adjust the curvature with rad parameter\n",
    "\n",
    "for idx, (community, color) in enumerate(zip(community_list, lighter_community_colors)):  # Use lighter colors\n",
    "    community_x = x_positions[np.isin(neuron_names, community)]\n",
    "    community_y = y_positions[np.isin(neuron_names, community)]\n",
    "    \n",
    "    # Add jitter to x and y positions\n",
    "    jittered_community_x = [x + random.uniform(-30, 30) for x in community_x]\n",
    "    jittered_community_y = [y + random.uniform(-30, 30) for y in community_y]\n",
    "    \n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 3 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    plt.scatter(jittered_community_x, jittered_community_y, label=f'Community {idx + 1}',\n",
    "                s=node_size, c=color, zorder=3, edgecolor='black', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Network Community Visualization (Real Position)')\n",
    "plt.grid(True, color='gray', alpha=0.2, linewidth=0.5)  # Adjust grid lines\n",
    "plt.axis('equal')  # Ensure aspect ratio is equal\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# Adjust the y-axis limits to -200 and 1600\n",
    "plt.ylim(-200, 1600)\n",
    "# Save the plot as PDF\n",
    "plt.savefig('network_community_visualization_poistionBased.pdf', format='pdf')\n",
    "# Save the plot as SVG\n",
    "plt.savefig('network_community_visualization_poistionBased.svg', format='svg')\n",
    "\n",
    "\n",
    "# Plot based on topological closeness using Kamada-Kawai layout\n",
    "plt.subplot(1, 2, 2)\n",
    "pos = nx.kamada_kawai_layout(G, scale=2.0)  # Using Kamada-Kawai layout with increased scale for node separation\n",
    "for idx, (community, color) in enumerate(zip(community_list, lighter_community_colors)):  # Use lighter colors\n",
    "    community_degrees = [node_degrees[node] for node in community]\n",
    "    node_size = [deg * 3 for deg in community_degrees]  # Adjust the multiplier as needed\n",
    "    \n",
    "    plt.scatter([pos[node][0] for node in community], [pos[node][1] for node in community], label=f'Community {idx + 1}',\n",
    "                s=node_size, c=color, zorder=3, edgecolor='black', linewidth=0.3)\n",
    "\n",
    "for source, target in G.edges():\n",
    "    pos_src = pos[source]\n",
    "    pos_tgt = pos[target]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[(source, target)], \n",
    "                           width=0.2, alpha=0.9, connectionstyle=\"arc3,rad=0.2\",\n",
    "                           edge_color='gray')  # Curved edges without arrowheads\n",
    "\n",
    "plt.title('Network Community Visualization (Kamada-Kawai Layout)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as PDF\n",
    "plt.savefig('network_community_visualization_Topology.pdf', format='pdf')\n",
    "# Save the plot as SVG\n",
    "plt.savefig('network_community_visualization_Topology.svg', format='svg')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "############################################ Plot community-based Hetmaps #################################\n",
    "\n",
    "# Print communities\n",
    "for idx, community in enumerate(community_list):\n",
    "    print(f\"Community {idx + 1}: {community}\")\n",
    "\n",
    "# Extract ordered neurons  (neurons that are within communities will be selected)\n",
    "ordered_neurons = [neuron for community in community_list for neuron in community]\n",
    "\n",
    "# Create a symmetric correlation matrix with ordered neurons\n",
    "# first: generates list of node pairs with their correlation coefficient attributed. \n",
    "# Then: it generates a symmetric matrix based on list \n",
    "ordered_data = pd.DataFrame(index=ordered_neurons, columns=ordered_neurons)\n",
    "for i, neuron_i in enumerate(ordered_neurons):\n",
    "    for j, neuron_j in enumerate(ordered_neurons):\n",
    "        correlation_coefficient = correlation_matrix.loc[neuron_i, neuron_j]\n",
    "        ordered_data.at[neuron_i, neuron_j] = correlation_coefficient\n",
    "        ordered_data.at[neuron_j, neuron_i] = correlation_coefficient\n",
    "\n",
    "\n",
    "# Ensure diagonal is zero\n",
    "np.fill_diagonal(ordered_data.values, 0)\n",
    "\n",
    "# Convert correlation coefficients to floats\n",
    "ordered_data = ordered_data.astype(float)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# Plot the heatmap with grayscale colormap\n",
    "sns.heatmap(ordered_data, cmap='Greys', vmin=ordered_data.values.max(), vmax=ordered_data.values.min(),\n",
    "            linewidths=0.5, linecolor='black', alpha=0.5, cbar=True, square=True, mask=ordered_data.isnull(),\n",
    "            annot=False, fmt='.2f')\n",
    "\n",
    "# Draw squares around neurons of each community with respective colors\n",
    "ax = plt.gca()\n",
    "start = 0\n",
    "for idx, community in enumerate(community_list):\n",
    "    end = start + len(community)\n",
    "    color = community_colors[idx]\n",
    "    rect = plt.Rectangle((start, start), end - start, end - start, linewidth=1, edgecolor=color, facecolor=color, alpha=0.5)\n",
    "    ax.add_patch(rect)\n",
    "    start = end\n",
    "\n",
    "plt.title('Community-Based Correlation Matrix Heatmap')\n",
    "plt.xlabel('Neurons')\n",
    "plt.ylabel('Neurons')\n",
    "\n",
    "# Save the plot as PDF\n",
    "plt.savefig('network_community_visualization_HeatMap.pdf', format='pdf')\n",
    "# Save the plot as SVG\n",
    "plt.savefig('network_community_visualization_HeatMap.svg', format='svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
